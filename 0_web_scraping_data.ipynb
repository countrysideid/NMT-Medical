{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "0_web_scraping_data.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Crawl Data from NEJM"
      ],
      "metadata": {
        "id": "NqUKRNQbFm31"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FsDSGnligMlL"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import re\n",
        "import os\n",
        "import glob\n",
        "from collections import defaultdict\n",
        "from copy import deepcopy\n",
        "import logging\n",
        "from datetime import datetime\n",
        "from time import sleep\n",
        "\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "from selenium.webdriver.common.by import By"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sys.path.append(\".\")\n",
        "from utils.utils import Container"
      ],
      "metadata": {
        "id": "fYspm4mmFUNk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace these with your NEJM credentials\n",
        "nejm_username = \"######\"\n",
        "nejm_password = \"######\"\n",
        "\n",
        "\n",
        "# Global variables:\n",
        "out_dir = \"../processed_data/crawler/nejm/urls/\"\n",
        "article_dir = \"../processed_data/crawler/nejm/articles/\"\n",
        "\n",
        "traverse = True # Whether to get the article urls.\n",
        "crawl = True # Whether to get the article content.\n",
        "os.makedirs(out_dir, exist_ok=True)\n",
        "os.makedirs(article_dir, exist_ok=True)\n"
      ],
      "metadata": {
        "id": "0PkPQIqHFUQd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#####################\n",
        "# Utility Functions #\n",
        "#####################\n",
        "def print_and_log(message):\n",
        "\tprint(message, flush=True)\n",
        "\tlogging.info(message)\n",
        "\n",
        "\n",
        "def detect_dialog_window(driver):\n",
        "\n",
        "\twindow = driver.find_elements_by_xpath(\\\n",
        "\t\t\"//div[@class='featherlight-content']\")\n",
        "\tif window != []:\n",
        "\t\treturn True\n",
        "\telse:\n",
        "\t\treturn False\n",
        "\n",
        "\n",
        "def close_dialog_window(driver):\n",
        "\tclose_button = driver.find_element_by_xpath(\n",
        "\t\t\"//button[@class='featherlight-close-icon featherlight-close']\")\n",
        "\tclose_button.click()\n",
        "\n",
        "\n",
        "def nejm_signin(driver):\n",
        "\tdriver.get(\"https://www.nejm.org/\")\n",
        "\n",
        "\txpath_query = \"//a[@data-interactiontype='sign_in_click']\"\n",
        "\tsign_in_click = driver.find_element_by_xpath(xpath_query)\n",
        "\tsign_in_click.click()\n",
        "\n",
        "\tlogin = driver.find_element_by_id(\"login\")\n",
        "\tlogin.send_keys(nejm_username)\n",
        "\n",
        "\tpassword = driver.find_element_by_id(\"password\")\n",
        "\tpassword.send_keys(nejm_password)\n",
        "\n",
        "\tdriver.find_element_by_id(\"btnSignIn\").click()\n",
        "\tprint(\"Signed in to NEJM.\")\n",
        "\n",
        "\n",
        "def detect_paywall(driver):\n",
        "\txpath_query = \"//a[@class='o-gateway__button o-gateway__button--secondary'\" \\\n",
        "\t\t\t\t  \" and @data-interactiontype='subscribe_click']\"\n",
        "\n",
        "\tpaywall = driver.find_elements_by_xpath(xpath_query)\n",
        "\tif paywall != []:\n",
        "\t\tnejm_signin(driver)\n",
        "\n",
        "\n",
        "def nejm_signout(driver):\n",
        "\txpath_query = \"//a[@data-interactiontype='sign_out_click']\"\n",
        "\tdriver.find_elements_by_xpath(xpath_query)[0].click()\n",
        "\n",
        "\n",
        "def yxqy_login(driver):\n",
        "\n",
        "\tdriver.get(\"https://www.nejmqianyan.cn/index.php?c=week&m=year\")\n",
        "\ttry:\n",
        "\t\txpath_query = \"//a[@href='javascript:;' and @class='dropdown-toggle']\"\n",
        "\t\tdropdown = driver.find_element_by_xpath(xpath_query)\n",
        "\t\tdropdown.click()\n",
        "\t\tmembername = driver.find_element_by_name(\"membername\")\n",
        "\t\tmembername.clear()\n",
        "\t\tmembername.send_keys(\"publicuser\")\n",
        "\n",
        "\t\tpassword = driver.find_element_by_name(\"password\")\n",
        "\t\tpassword.clear()\n",
        "\t\tpassword.send_keys(\"publicuser\")\n",
        "\n",
        "\t\tlogin = driver.find_element_by_class_name(\\\n",
        "\t\t\t\"btn.btn-default.fastLoginBtn.login-top\")\n",
        "\t\tlogin.click()\n",
        "\t\tsleep(2)\n",
        "\n",
        "\texcept:\n",
        "\t\tprint(\"Already logged in to YXQY!\")\n",
        "\t\tlogged_in = True\n",
        "\n",
        "\n",
        "def jw_login(driver):\n",
        "\ttry:\n",
        "\t\temail = driver.find_element_by_xpath(\\\n",
        "\t\t\t\"//article-page//input[@id='email_text']\")\n",
        "\t\temail.clear()\n",
        "\t\temail.send_keys(\"bliuforgit@gmail.com\")\n",
        "\t\tpassword = driver.find_element_by_xpath(\\\n",
        "\t\t\t\"//article-page//input[@id='pwd_text']\")\n",
        "\t\tpassword.clear()\n",
        "\t\tpassword.send_keys(\"password\")\n",
        "\t\tlogin = driver.find_element_by_xpath(\\\n",
        "\t\t\t\"//article-page//button\")\n",
        "\t\tlogin.click()\n",
        "\t\tsleep(3)\n",
        "\n",
        "\texcept:\n",
        "\t\tprint(\"Already logged into Journal Watch!\")\n",
        "\t\tlogged_in = True\n"
      ],
      "metadata": {
        "id": "DW8KBDqvFUTD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "######################\n",
        "# Crawling Functions #\n",
        "######################\n",
        "def crawl_zh_page(driver, article_id, zh_url, out_prefix, verbose=False):\n",
        "\tdriver.get(zh_url)\n",
        "\tprint_and_log(f\"Crawling Chinese article: {article_id}.\")\n",
        "\n",
        "\tfull_article = driver.find_element_by_id(\"nejm-article-content\").text\n",
        "\tfull_text = [x.strip() for x in full_article.split(\"\\n\")]\n",
        "\n",
        "\twith open(f\"{out_prefix}.full.zh\", \"w\") as f:\n",
        "\t\tfor i in full_text:\n",
        "\t\t\tf.write(i + \"\\n\")\n",
        "\n",
        "\n",
        "def crawl_en_page(driver, article_id, en_url, out_prefix, verbose=False):\n",
        "\n",
        "\tdriver.get(en_url)\n",
        "\tif detect_dialog_window(driver):\n",
        "\t\tclose_dialog_window(driver)\n",
        "\n",
        "\t# Sign in if paywalled.\n",
        "\tdetect_paywall(driver)\n",
        "\n",
        "\tprint_and_log(f\"Crawling English article: {article_id}.\")\n",
        "\tarticle_type = re.sub(\"[0-9]+\", \"\", article_id).replace(\"%\", \"\")\n",
        "\tprint_and_log(f\"Article type: {article_type}.\")\n",
        "\n",
        "\t# Crawl article from NEJM website\n",
        "\tif article_type != \"jw.na\":\n",
        "\t\tsleep(1)\n",
        "\t\tfull_article = driver.find_element_by_id(\"full\").text\n",
        "\t\tfull_text = [x.strip() for x in full_article.split(\"\\n\")]\n",
        "\n",
        "\t\ttry:\n",
        "\t\t\tboxed_text = driver.find_element_by_class_name(\"m-boxed-text\").text\n",
        "\t\t\tfull_text_no_box = [x.strip() for x in \\\n",
        "\t\t\t\tfull_article.replace(boxed_text, \"\").split(\"\\n\")]\n",
        "\t\t\tprint(\"Found boxed text.\")\n",
        "\t\texcept:\n",
        "\t\t\tfull_text_no_box = full_text\n",
        "\t\t\tprint(\"No boxed text.\")\n",
        "\n",
        "\t# Crawl article from Journal Watch website\n",
        "\telse:\n",
        "\t\ttry:\n",
        "\t\t\tWebDriverWait(driver, timeout=60).\\\n",
        "\t\t\t\tuntil(EC.presence_of_element_located(\\\n",
        "\t\t\t\t\t(By.CLASS_NAME, \"article-detail\")))\n",
        "\t\t\tsleep(1)\n",
        "\t\texcept:\n",
        "\t\t\tprint(\"Timeout!\")\n",
        "\t\t\treturn\n",
        "\n",
        "\t\tjw_login(driver)\n",
        "\t\tfull_article = driver.find_element_by_class_name(\"article-detail\").text\n",
        "\t\tfull_text = [x.strip() for x in full_article.split(\"\\n\")]\n",
        "\t\tfull_text_no_box = full_text\n",
        "\n",
        "\twith open(f\"{out_prefix}.full.en\", \"w\") as f:\n",
        "\t\tfor i in full_text:\n",
        "\t\t\tf.write(i + \"\\n\")\n",
        "\n",
        "\twith open(f\"{out_prefix}.nobox.en\", \"w\") as f:\n",
        "\t\tfor i in full_text_no_box:\n",
        "\t\t\tf.write(i + \"\\n\")\n",
        "\n",
        "\n",
        "def compare_zh_and_en(zh_fn, en_fn, epsilon = 2):\n",
        "\twith open(zh_fn, \"r\") as f_zh, \\\n",
        "\t\topen(en_fn, \"r\") as f_en:\n",
        "\t\tzh = f_zh.readlines()\n",
        "\t\ten = f_en.readlines()\n",
        "\n",
        "\tzh = [x for x in zh if x.strip() != \"\"]\n",
        "\ten = [x for x in en if x.strip() != \"\"]\n",
        "\tzh_len, en_len = len(zh), len(en)\n",
        "\t\n",
        "\tif en_len == 0 or zh_len == 0:\n",
        "\t\tcomparison = \"empty_article\"\n",
        "\n",
        "\telse:\n",
        "\t\tif en_len / zh_len > epsilon:\n",
        "\t\t\tcomparison = \"en_too_long\"\n",
        "\t\telif zh_len / en_len > epsilon:\n",
        "\t\t\tcomparison = \"zh_too_long\"\n",
        "\t\telse:\n",
        "\t\t\tcomparison = \"equal\"\n",
        "\n",
        "\treturn comparison, zh_len, en_len \n",
        "\n",
        "\n",
        "def crawl_all_urls(driver, container):\n",
        "\n",
        "\ttotal = len([_ for i in container.values() \\\n",
        "\t\tfor j in i.values() for k in j.values()])\n",
        "\n",
        "\tn = 0\n",
        "\tfor year, month_dict in container.items():\n",
        "\t\t\n",
        "\t\tprint_and_log(\"#############\")\n",
        "\t\tprint_and_log(f\"# Year {year} #\")\n",
        "\t\tprint_and_log(\"#############\")\n",
        "\n",
        "\t\tfor month, article_dict in month_dict.items():\n",
        "\t\t\tos.makedirs(os.path.join(article_dir, year, month), exist_ok=True)\n",
        "\n",
        "\t\t\tprint_and_log(\"####################\")\n",
        "\t\t\tprint_and_log(f\"# Crawling {year}/{month} #\")\n",
        "\t\t\tprint_and_log(\"####################\")\n",
        "\n",
        "\t\t\tfor article_id, (zh_title, en_title, zh_url, en_url) in article_dict.items():\n",
        "\n",
        "\t\t\t\tif n % 100 == 0:\n",
        "\t\t\t\t\tmessage = f\"### Progress: {n}/{total} Articles ###\"\n",
        "\t\t\t\t\tprint_and_log(message)\n",
        "\n",
        "\t\t\t\tmessage = f\"Article: {zh_title}/{en_title}\"\n",
        "\t\t\t\tprint_and_log(message)\n",
        "\n",
        "\t\t\t\tout_prefix = f\"{article_dir}/{year}/{month}/{article_id}\"\n",
        "\t\t\t\tzh_out = f\"{out_prefix}.full.zh\"\n",
        "\t\t\t\ten_out = f\"{out_prefix}.nobox.en\"\n",
        "\n",
        "\t\t\t\t# Crawl articles:\n",
        "\t\t\t\tif not os.path.exists(zh_out):\n",
        "\t\t\t\t\tcrawl_zh_page(driver, article_id, zh_url, out_prefix)\n",
        "\t\t\t\tif not os.path.exists(en_out):\n",
        "\t\t\t\t\tcrawl_en_page(driver, article_id, en_url, out_prefix)\n",
        "\n",
        "\t\t\t\tn += 1"
      ],
      "metadata": {
        "id": "UOEizsYwFUVe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "container = Container()\n",
        "container.read_from_disk(out_dir)\n",
        "\n",
        "# Traversing the NEJM website.\n",
        "if traverse:\n",
        "  container.traverse(driver, out_dir)\n",
        "\n",
        "# Logging:\n",
        "if crawl:\n",
        "  log_fn = \"{}/article.log\".format(article_dir)\n",
        "  logging.basicConfig(filename=log_fn, \\\n",
        "    format=\"%(message)s\", level=logging.DEBUG)\n",
        "  crawl_all_urls(driver, container)\n",
        "\n",
        "nejm_signout(driver)"
      ],
      "metadata": {
        "id": "cxYdarY2FeqG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocess data"
      ],
      "metadata": {
        "id": "PaEhSGhkFlc_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import sys\n",
        "sys.path.append(\".\")\n",
        "from utils.utils import read_article_urls\n",
        "\n",
        "url_dir = \"../processed_data/crawler/nejm/urls/\"\n",
        "article_dir = \"../processed_data/crawler/nejm/articles/\"\n",
        "\n",
        "def read_article(fn):\n",
        "\twith open(fn, \"r\") as f: \n",
        "\t\tx = f.readlines()\n",
        "\treturn x\n"
      ],
      "metadata": {
        "id": "yddv9yi1FvOY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Stitch two or more sentences into one\n",
        "# Why? Because sometime a single sentence \n",
        "# are broken into muliple piece on the website.\n",
        "def stitch(article, lang):\n",
        "\tif lang == \"zh\":\n",
        "\t\tfor i, _ in enumerate(article):\n",
        "\t\t\t# A line with only numbers (i.e citation)\n",
        "\t\t\tif re.fullmatch(\"^[0-9,-]+\\n$\", article[i]):\n",
        "\t\t\t\tif article[i].endswith(\"\\n\"):\n",
        "\t\t\t\t\tarticle[i] = article[i].replace(\"\\n\", \"\")\n",
        "\t\t\t\tif article[i-1].endswith(\"\\n\"):\n",
        "\t\t\t\t\tarticle[i-1] = article[i-1].replace(\"\\n\", \"\")\n",
        "\t\t\t# A line with open a period\n",
        "\t\t\tif re.fullmatch(\"^。$\", article[i]):\n",
        "\t\t\t\tif article[i-1].endswith(\"\\n\"):\n",
        "\t\t\t\t\tarticle[i-1] = article[i-1].replace(\"\\n\", \"\")\n",
        "\n",
        "\telif lang == \"en\":\n",
        "\t\tfor i, _ in enumerate(article):\n",
        "\t\t\t# A line with a hyperlink\n",
        "\t\t\tif article[i].strip() == \". opens in new tab\":\n",
        "\t\t\t\tarticle[i] = \"\"\n",
        "\t\t\t\tif article[i-1].endswith(\"\\n\"):\n",
        "\t\t\t\t\tarticle[i-1] = article[i-1].replace(\"\\n\", \"\")\n",
        "\n",
        "\tfull_text = \"\".join(article)\n",
        "\tarticle = full_text.split(\"\\n\")\n",
        "\treturn article\n",
        "\n",
        "\n",
        "def filter(article, article_type, lang):\n",
        "\tkeep = [True] * len(article)\n",
        "\n",
        "\t# Remove correspondence and \n",
        "\t# image in clinical medicine\n",
        "\tif article_type in [\"c\", \"icm\"]: \n",
        "\t\treturn [] \n",
        "\n",
        "\tif lang == \"zh\":\n",
        "\t\tfor i, text in enumerate(article):\n",
        "\n",
        "\t\t\t#############################\n",
        "\t\t\t# Remove text in the middle #\n",
        "\t\t\t#############################\n",
        "\t\t\t# Remove tables and figures\n",
        "\t\t\tif re.match(\"图[0-9]{1,2}\\.\", text):\n",
        "\t\t\t\tkeep[i] = keep[i+1] = False\n",
        "\t\t\telif re.match(\"表[0-9]{1,2}\\.\", text):\n",
        "\t\t\t\tkeep[i] = False\n",
        "\n",
        "\t\t\t# Remove table captions\n",
        "\t\t\telif text.startswith(\"*\") or \\\n",
        "\t\t\t\ttext.startswith(\"†\") or \\\n",
        "\t\t\t\ttext.startswith(\"‡\") or \\\n",
        "\t\t\t\ttext.startswith(\"§\") or \\\n",
        "\t\t\t\ttext.startswith(\"¶\") or \\\n",
        "\t\t\t\ttext.startswith(\"‖\") or \\\n",
        "\t\t\t\ttext.startswith(\"|\"):\n",
        "\t\t\t\tkeep[i] = False\n",
        "\n",
        "\t\t\t# Remove empty lines\n",
        "\t\t\telif text.strip() == \"\":\n",
        "\t\t\t\tkeep[i] = False\n",
        "\n",
        "\t\t\t######################\n",
        "\t\t\t# Remove text before #\n",
        "\t\t\t######################\n",
        "\t\t\tif article_type == \"clde\":\n",
        "\t\t\t\tif text.strip() == \"案例摘要\" or \\\n",
        "\t\t\t\t\ttext.strip() == \"病例摘要\":\n",
        "\t\t\t\t\tfor j in range(i):\n",
        "\t\t\t\t\t\tkeep[j] = False\n",
        "\n",
        "\t\t\t#####################\n",
        "\t\t\t# Remove text after #\n",
        "\t\t\t#####################\n",
        "\t\t\tif article_type == \"jw.na\": # Journal Watch\n",
        "\t\t\t\tif text.startswith(\"出版时\") or \\\n",
        "\t\t\t\t\ttext.startswith(\"引文\"):\n",
        "\t\t\t\t\tfor j in range(i, len(keep)):\n",
        "\t\t\t\t\t\tkeep[j] = False\n",
        "\t\t\t\t\tbreak\n",
        "\n",
        "\t\t\t# Original Article\n",
        "\t\t\t# Review Article\n",
        "\t\t\t# Case Records\n",
        "\t\t\t# Perspective\n",
        "\t\t\t# Editorial\n",
        "\t\t\t# Clinical Problem solving\n",
        "\t\t\t# Clinical Implications of Basic Research\n",
        "\t\t\t# Special report\n",
        "\t\t\t# Special article\n",
        "\t\t\t# Clinical therapeutics\n",
        "\t\t\t# Health policy report\n",
        "\t\t\t# Clinical practice\n",
        "\t\t\t# Medicine and Society\n",
        "\t\t\telif article_type in [\"oa\", \"ra\", \"cpc\", \"p\", \"ms\",\\\n",
        "\t\t\t\t\"e\", \"cps\", \"cibr\", \"sr\", \"sa\", \"ct\", \"hpr\", \"cp\"] : \n",
        "\t\t\t\tif text.startswith(\"Disclosure\") or \\\n",
        "\t\t\t\t\ttext.startswith(\"译者\") or \\\n",
        "\t\t\t\t\ttext.startswith(\"作者信息\"):\n",
        "\t\t\t\t\tfor j in range(i, len(keep)):\n",
        "\t\t\t\t\t\tkeep[j] = False\n",
        "\t\t\t\t\tbreak\n",
        "\t\t\t# Corrections\n",
        "\t\t\telif article_type == \"x\": \n",
        "\t\t\t\tif text.startswith(\"译者\"):\n",
        "\t\t\t\t\tfor j in range(i, len(keep)):\n",
        "\t\t\t\t\t\tkeep[j] = False\n",
        "\t\t\t\t\tbreak\n",
        "\t\t\t# Clinical Decisions\n",
        "\t\t\telif article_type == \"clde\":\n",
        "\t\t\t\tif text.startswith(\"选项2\"):\n",
        "\t\t\t\t\tfor j in range(i, len(keep)):\n",
        "\t\t\t\t\t\tkeep[j] = False\n",
        "\t\t\t\t\tbreak\n",
        "\n",
        "\n",
        "\n",
        "\telif lang == \"en\":\n",
        "\t\tfor i, text in enumerate(article):\n",
        "\n",
        "\t\t\t#############################\n",
        "\t\t\t# Remove text in the middle #\n",
        "\t\t\t#############################\n",
        "\t\t\t# Remove Table and Figure\n",
        "\t\t\tif re.match(\"Table [0-9]{1,2}\\.\", text) or \\\n",
        "\t\t\t\tre.match(\"Figure [0-9]{1,2}\\.\", text):\n",
        "\t\t\t\tkeep[i] = keep[i+1] = False\n",
        "\t\t\t# Remove video and audio interviews:\n",
        "\t\t\telif text.strip() == \"Video\" or \\\n",
        "\t\t\t\ttext.strip() == \"Interactive Graphic\":\n",
        "\t\t\t\tkeep[i] = keep[i+1] = False\n",
        "\t\t\t# Audio interview:\n",
        "\t\t\telif text.strip() == \"Audio Interview\":\n",
        "\t\t\t\tkeep[i] = keep[i+1] = keep[i+2] = False\n",
        "\t\t\t# Remove QUICK TAKE:\n",
        "\t\t\telif text.strip() == \"QUICK TAKE\":\n",
        "\t\t\t\tkeep[i] = keep[i+1] = keep[i+2] = keep[i+3] = keep[i+4] = False\n",
        "\t\t\t# Remove VISUAL ABSTRACT:\n",
        "\t\t\telif text.strip() == \"VISUAL ABSTRACT\":\n",
        "\t\t\t\tkeep[i] = keep[i+1] = keep[i+2] = False\n",
        "\t\t\t# Remove intro and other text:\n",
        "\t\t\telif text.strip() == \"Letters\" or \\\n",
        "\t\t\t\ttext.strip() == \"Download\" or \\\n",
        "\t\t\t\ttext.strip() == \"Audio Full Text\" or \\\n",
        "\t\t\t\ttext.strip() == \"Key Clinical Points\" or \\\n",
        "\t\t\t\ttext.strip() == \"Poll\" or \\\n",
        "\t\t\t\ttext.startswith(\"Comments open through\") or \\\n",
        "\t\t\t\ttext.startswith(\"Citing Article\") or \\\n",
        "\t\t\t\ttext.startswith(\"Option 1\") or \\\n",
        "\t\t\t\ttext.startswith(\"Option 2\") or \\\n",
        "\t\t\t\tre.match(\"^[0-9]+ Reference\", text) or \\\n",
        "\t\t\t\tre.match(\"^[0-9]+ Citing Article\", text) or \\\n",
        "\t\t\t\tre.match(\"^[0-9]+ Comment\", text):\n",
        "\t\t\t\tkeep[i] = False\n",
        "\t\t\t# Remove sign-ups\n",
        "\t\t\telif text.startswith(\"Sign up for\"):\n",
        "\t\t\t\tkeep[i] = False\n",
        "\t\t\telif text.strip() == \"\":\n",
        "\t\t\t\tkeep[i] = False\n",
        "\n",
        "\t\t\t######################\n",
        "\t\t\t# Remove text before #\n",
        "\t\t\t######################\n",
        "\t\t\tif article_type == \"jw.na\":\n",
        "\t\t\t\tfor j in range(5): # Remove first 5 lines\n",
        "\t\t\t\t\tkeep[j] = False\n",
        "\t\t\telif article_type == \"oa\": # Original Article\n",
        "\t\t\t\tif text.strip() == \"Abstract\":\n",
        "\t\t\t\t\tfor j in range(i):\n",
        "\t\t\t\t\t\tkeep[j] = False\n",
        "\t\t\telif article_type == \"cpc\": # Case Records\n",
        "\t\t\t\tif text.strip() == \"Presentation of Case\":\n",
        "\t\t\t\t\tfor j in range(i):\n",
        "\t\t\t\t\t\tkeep[j] = False\n",
        "\n",
        "\t\t\t#####################\n",
        "\t\t\t# Remove text after #\n",
        "\t\t\t#####################\n",
        "\t\t\tif article_type == \"jw.na\":\n",
        "\t\t\t\tif text.startswith(\"EDITOR DISCLOSURES AT TIME OF PUBLICATION\") or \\\n",
        "\t\t\t\t\ttext.startswith(\"CITATION\"):\n",
        "\t\t\t\t\tfor j in range(i, len(keep)):\n",
        "\t\t\t\t\t\tkeep[j] = False\n",
        "\t\t\t\t\tbreak\n",
        "\n",
        "\t\t\t# Original Article\n",
        "\t\t\t# Review Article\n",
        "\t\t\t# Case Records\n",
        "\t\t\t# Perspective\n",
        "\t\t\t# Editorial\n",
        "\t\t\t# Clinical Problem Solving\n",
        "\t\t\t# Clinical Implications of Basic Research\n",
        "\t\t\t# Special report\n",
        "\t\t\t# Clinical decision\n",
        "\t\t\t# Special article\n",
        "\t\t\t# Clinical Therapeutics\n",
        "\t\t\t# Health policy report\n",
        "\t\t\t# Clinical Practice\n",
        "\t\t\t# Medicine and Society\n",
        "\t\t\telif article_type in [\"oa\", \"ra\", \"cpc\", \"p\", \"e\", \"ms\",\\\n",
        "\t\t\t\t\"cps\", \"cibr\", \"sr\", \"clde\", \"sa\", \"ct\", \"hpr\", \"cp\"]: \n",
        "\t\t\t\tif text.startswith(\"Disclosure\"):\n",
        "\t\t\t\t\tfor j in range(i, len(keep)):\n",
        "\t\t\t\t\t\tkeep[j] = False\n",
        "\t\t\t\t\tbreak\n",
        "\n",
        "\t# Output to disk\n",
        "\tarticle_filt = []\n",
        "\tfor a, k in zip(article, keep):\n",
        "\t\tif k == True:\n",
        "\t\t\tarticle_filt.append(a)\n",
        "\n",
        "\treturn article_filt\n"
      ],
      "metadata": {
        "id": "1OsaiYrcFzxv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "meta = read_article_urls(url_dir)\n",
        "meta = meta[meta[\"year\"] != 2020] # Remove year 2020\n",
        "\n",
        "for index, row in meta.iterrows():\n",
        "year = row[\"year\"]\n",
        "month = row[\"month\"]\n",
        "article_id = row[\"id\"]\n",
        "article_type = re.sub(\"[0-9%]+\", \"\", article_id)\n",
        "\n",
        "\n",
        "\n",
        "zh_fn = f\"{article_dir}/{year}/{month:02}/{article_id}.full.zh\"\n",
        "en_fn = f\"{article_dir}/{year}/{month:02}/{article_id}.nobox.en\"\n",
        "\n",
        "print(f\"path: {zh_fn}\")\n",
        "zh_article = read_article(zh_fn)\n",
        "zh_article = stitch(zh_article, \"zh\")\n",
        "zh_article = filter(zh_article, article_type, \"zh\")\n",
        "\n",
        "\n",
        "print(f\"path: {en_fn}\")\n",
        "en_article = read_article(en_fn)\n",
        "en_article = stitch(en_article, \"en\")\n",
        "en_article = filter(en_article, article_type, \"en\")\n",
        "\n",
        "intersect = set(zh_article).intersection(set(en_article))\n",
        "\n",
        "zh_out_fn = zh_fn.replace(\".full.\", \".filt.\")\n",
        "with open(zh_out_fn, \"w\") as f: \n",
        "  for line in zh_article:\n",
        "    if line not in intersect:\n",
        "      f.write(line + \"\\n\")\n",
        "\n",
        "en_out_fn = en_fn.replace(\".nobox.\",\".filt.\")\n",
        "with open(en_out_fn, \"w\") as f:\n",
        "  for line in en_article:\n",
        "    if line not in intersect:\n",
        "      f.write(line + \"\\n\")\n"
      ],
      "metadata": {
        "id": "9qUovluxF44X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Normalize and Split paragraphs into sentences"
      ],
      "metadata": {
        "id": "4i6Rsl_WGBYC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!normalize.sh"
      ],
      "metadata": {
        "id": "L4AW1wZFGHkl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!eserix.sh"
      ],
      "metadata": {
        "id": "LkpdpQqqGINP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Align sentences"
      ],
      "metadata": {
        "id": "yVdW5RSvG5tG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!alignment/moore/input.sh\n",
        "!alignment/moore/align.sh"
      ],
      "metadata": {
        "id": "-CRfPIwjGILZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!clean/concat.sh\n",
        "!clean/clean.sh\n",
        "# Split the data into train, dev and test:\n",
        "# Run the following to split data into train (~ 93000), development (~ 2000), and test (~ 2000):\n",
        "!split_data/split_train_test.py"
      ],
      "metadata": {
        "id": "WPyCxys4GII8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "bGLBjorVGIGO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}